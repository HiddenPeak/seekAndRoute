# Jetson 构建镜像流程

``` bash
cd ~/nvidia/nvidia_sdk/JetPack_6.2_Linux_JETSON_AGX_ORIN_TARGETS/Linux_for_Tegra
# 构建根文件系统
cd tools/samplefs
sudo ./nv_build_samplefs.sh --abi aarch64 --distro ubuntu --flavor minimal --version jammy


# 1. 切换到正确的目录
cd ~/nvidia/nvidia_sdk/JetPack_6.2_Linux_JETSON_AGX_ORIN_TARGETS/Linux_for_Tegra
# 2. 删除 rootfs/ 下的现有内容
# 注意：这个命令会递归删除 rootfs/ 目录下的所有文件和子目录。请务必确认你在正确的目录下！
sudo rm -rf rootfs/*
# 3. 解压 sample_fs.tbz2 到 rootfs/
# 假设 sample_fs.tbz2 位于 tools/samplefs/ 目录下
sudo tar -jxpf tools/samplefs/sample_fs.tbz2 -C rootfs/


# 应用二进制文件 工厂配置
cd ~/nvidia/nvidia_sdk/JetPack_6.2_Linux_JETSON_AGX_ORIN_TARGETS/Linux_for_Tegra
sudo ./apply_binaries.sh

# 创建OEM信息
sudo tools/l4t_create_default_user.sh -u rm01 -p a770 -n agx --accept-license

# 挂载必要的文件系统
cd ~/nvidia/nvidia_sdk/JetPack_6.2_Linux_JETSON_AGX_ORIN_TARGETS/Linux_for_Tegra/rootfs
sudo mount --bind /dev dev
sudo mount --bind /proc proc
sudo mount --bind /sys sys
sudo mount --bind /dev/pts dev/pts

# 为了让chroot环境能够访问网络（例如安装软件包），需要复制主机的DNS配置文件：
sudo cp /etc/resolv.conf etc/resolv.conf

# 修改APT源


# 使用 qemu-aarch64-static 进入目标文件系统的chroot环境
sudo apt update
sudo apt install -y qemu-user-static binfmt-support
sudo chroot . qemu-aarch64-static /bin/bash

# 在chroot环境中，更新apt索引以确保可以安装软件：
apt update

# 直接安装jetpack
apt --fix-broken install
sudo apt install nvidia-jetpack

# 手动安装系统工具
sudo apt update
sudo apt upgrade
sudo apt install -y nano ccache network-manager

# 安装jtop
sudo apt update
sudo apt install -y  python3 python3-pip
sudo -H pip3 install jetson-stats

# 结束后取消绑定的挂载
sudo umount rootfs/dev/pts
sudo umount rootfs/sys
sudo umount rootfs/proc
sudo umount rootfs/dev



# 启用恢复模式
sudo ./flash.sh rm01-orin mmcblk0p1

# 启动性能模式
sudo nvpmodel -m 0

# 完成烧录后
sudo ip link set enP1p1s0 up
sudo ip addr add 10.10.99.98/24 dev enP1p1s0
sudo ip route add default via 10.10.99.100
echo "nameserver 8.8.8.8" | sudo tee /etc/resolv.conf
# 配置 dns 服务器



# 安装jtop
sudo apt update
sudo apt install python3
sudo apt install python3-pip

sudo -H pip3 install jetson-stats
sudo systemctl restart jtop.service

# 运行
jtop

# 解锁功率
sudo nvpmodel -m 0
sudo jetson_clocks
```

确保NetworkManager管理网络

``` bash
sudo nano /etc/NetworkManager/NetworkManager.conf
```

确保内容如下：

``` ini
[main]
plugins=ifupdown,keyfile

[ifupdown]
managed=true
```

``` bash
# 保存文件后，重启 NetworkManager 服务
sudo systemctl restart NetworkManager

# 检查链接状态
nmcli device status
```

``` bash
# 修改连接名称 （名称根据nmcli device status结果确定）
sudo nmcli connection modify "enP1p1s0" connection.id RMinteNetwork
# 修改部分配置静态 IP 地址和网关
sudo nmcli connection modify RMinteNetwork \
    ipv4.method manual \
    ipv4.addresses 10.10.99.98/24 \
    ipv4.gateway 10.10.99.100
# （可选）配置 DNS
sudo nmcli connection modify RMinteNetwork ipv4.dns "8.8.8.8 8.8.4.4"


# 
sudo nmcli connection add type ethernet ifname "enP1p1s0" con-name RMinteNetwork \
    ipv4.method manual \
    ipv4.addresses 10.10.99.98/24 \
    ipv4.gateway 10.10.99.100 \
    ipv4.dns "8.8.8.8 8.8.4.4"
# 重新启动连接
sudo nmcli connection down RMinteNetwork
sudo nmcli connection up RMinteNetwork
# 检查链接状态
nmcli device status

# 调整 控制台输出信息级别 kernel.printk = 4 4 1 7
sudo nano /etc/sysctl.conf
# 启用
sudo sysctl -p

# 直接安装全部jetpack
sudo apt update
sudo apt install nvidia-jetpack

# 添加环境变量
echo 'export PATH=/usr/local/cuda/bin:$PATH' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc


# 修改软连接，调整默认版本
sudo rm /usr/local/cuda
sudo ln -s /usr/local/cuda-12.9 /usr/local/cuda
```

安装 cuda (libcusparselt0 )

``` bash
# cuda 安装
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/arm64/cuda-keyring_1.1-1_all.deb
sudo dpkg -i cuda-keyring_1.1-1_all.deb
sudo apt-get update
sudo apt-get -y install cuda-toolkit-12-9 cuda-compat-12-9 
sudo apt-get -y install libcusparselt0 libcusparselt-dev cudss libnvvpi3 cudnn
```

编辑 ~/.bashrc： 以 rm01 用户身份登录，编辑 ~/.bashrc：

```bash
nano ~/.bashrc
```

添加环境变量： 在文件末尾添加以下两行：

```bash
export PATH=$PATH:/usr/local/cuda-12.9/bin
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-12.9/lib64
# 采用不超过12的最新版本默认12.6
export PATH=$PATH:/usr/local/cuda-12.6/bin
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-12.6/lib64
```

应用更改： 使更改立即生效：

```bash
source ~/.bashrc
```

验证： 检查环境变量是否更新：

```bash
echo $PATH
```

应包含 :/usr/local/cuda-12.9/bin。

```bash
echo $LD_LIBRARY_PATH
```

应包含 /usr/local/cuda-12.9/lib64。

测试 CUDA 工具： 验证 CUDA 是否可用：

```bash
nvcc --version
```

这应返回 CUDA 编译器版本。

安装tensor RT

```bash
wget https://developer.nvidia.com/downloads/compute/machine-learning/tensorrt/10.7.0/local_repo/nv-tensorrt-local-tegra-repo-ubuntu2204-10.7.0-cuda-12.6_1.0-1_arm64.deb
sudo dpkg -i nv-tensorrt-local-tegra-repo-ubuntu2204-10.7.0-cuda-12.6_1.0-1_arm64.deb
sudo cp /var/nv-tensorrt-local-tegra-repo-ubuntu2204-10.7.0-cuda-12.6/*-keyring.gpg /usr/share/keyrings/
sudo apt-get update
sudo apt install tensorrt
```



安装conda

``` bash
mkdir -p ~/miniconda3
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh  -O ~/miniconda3/miniconda.sh
bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3
rm ~/miniconda3/miniconda.sh

source ~/miniconda3/bin/activate

conda init --all
```

创建vllm085p1环境 (文件经由刷机设备scp到jetson)

``` bash
conda create -n vllm085p1 python=3.12
conda activate vllm085p1
export TORCH_CUDA_ARCH_LIST=8.7
vllm serve "Qwen/Qwen3-0.6B"
# 或者下载后
vllm serve "/home/rm01/testModels/Qwen/Qwen3-0.6B/"


curl http://localhost:8000/v1/completions \
    -H "Content-Type: application/json" \
    -d '{
        "model": "Qwen/Qwen3-0.6B",
        "prompt": "San Francisco is a",
        "max_tokens": 7,
        "temperature": 0
    }'
```

安装TEI

``` bash
# 安装系统依赖 参考N305安装脚本的基础依赖
sudo apt update
sudo apt install -y gpg-agent wget libssl-dev pkg-config protobuf-compiler curl git
# 检查 PATH 环境变量 查看是否包含 cuda 的 bin 路径
echo $PATH
# 安装 Rust 使用默认安装，确保所有下载正确，并安装完成再进入下一步
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
# 安装缓存工具
cargo install sccache
export RUSTC_WRAPPER=sccache
# 启用环境变量
. "$HOME/.cargo/env"

# 添加 musl 
rustup target add aarch64-unknown-linux-musl
sudo apt-get install musl-tools

# 利用已经编译的压缩文件
tar -xvzf text-embeddings-inference.tar.gz

# 拉取TEI
git clone https://github.com/huggingface/text-embeddings-inference.git
cd text-embeddings-inference
# 修改文件 参考https://github.com/huggingface/text-embeddings-inference/pull/467/files
nano backends/candle/src/compute_cap.rs
# 安装
cargo install --path router -F candle-cuda -F http -F static-linking --no-default-features
# 验证缓存效果
sccache --show-stats
# 验证安装情况
text-embeddings-router --version
```

创建全面监测

### 安装 jetson_stats_node_exporter

https://github.com/laminair/jetson_stats_node_exporter

``` bash
# 创建conda环境
conda create -n jtopenv python=3.12
# 拷贝文件
cp /usr/lib/aarch64-linux-gnu/libstdc++.so.6 ~/miniconda3/envs/jtopenv/lib/
# 激活环境
conda activate jtopenv
# 安装 jtop 监控 exporter
pip install jetson-stats-node-exporter==0.1.1
# 执行 jetson-stats-node-exporter ，并配置端口 59100
python3 -m jetson_stats_node_exporter --port 59100
# 创建服务文件
sudo nano /etc/systemd/system/jetson-stats-gpu-node-exporter.service
```

``` ini
[Unit]
Description=Jetson Stats GPU Node Exporter
After=jtop.service multi-user.target

[Service]
Type=simple
Restart=on-failure
RestartSec=10
User=rm01
Group=rm01
ExecStartPre=/bin/sleep 10
Environment="PATH=/home/rm01/miniconda3/envs/jtopenv/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin"
WorkingDirectory=/home/rm01
ExecStart=/bin/bash -c "source /home/rm01/miniconda3/etc/profile.d/conda.sh && conda activate jtopenv && python3 -m jetson_stats_node_exporter --port 59100"
[Install]
WantedBy=multi-user.target
```

启动并启用服务

``` bash
sudo systemctl daemon-reload
sudo systemctl enable jetson-stats-gpu-node-exporter
sudo systemctl start jetson-stats-gpu-node-exporter
```

查看服务状态和日志

``` bash
sudo systemctl status jetson-stats-gpu-node-exporter
journalctl -u jetson-stats-gpu-node-exporter
# 测试
curl http://10.10.99.98:59100/metrics
```

### 

自动挂载cfe

### 一、CFE磁盘准备

大于128GB，若启动硬盘休眠需要超过256GB

#### （一）格式化磁盘

``` bash
# 安装exfat依赖
sudo apt update
sudo apt install exfat-fuse exfatprogs

# 验证工具是否安装正确 （如果返回类似 /usr/bin/mount.exfat-fuse 的路径，说明工具已正确安装。）
which mount.exfat-fuse

# 查看磁盘信息 （确保目标磁盘是 nvme0n1）
lsblk

# 创建分区 （1.输入 g 创建 GPT 分区表；2.输入 w 保存并退出）
sudo fdisk /dev/nvme0n1

# 创建新分区 （1.输入 n 创建新分区；2.按提示选择分区号、起始扇区和结束扇区（默认值通常即可）；3.输入 t 设置分区类型，选择 7（Microsoft basic data，适用于 exFAT）；4.输入 w 保存并退出；）
sudo fdisk /dev/nvme0n1

# 命令格式化为 exFAT （假设新分区是 nvme0n1p1）
sudo mkfs.exfat /dev/nvme0n1p1
```

格式化磁盘与extfat类似选择分区类型和格式化mkfs的时候选择ext4即可

#### （二）配置rm01cfe标签

``` bash
# 配置标签
sudo exfatlabel /dev/nvme0n1p1 rm01cfe

# 检查标签 （正确输出为：rm01cfe）
sudo exfatlabel /dev/nvme0n1p1

# 若选择ext4格式磁盘
# 配置标签
sudo e2label /dev/nvme0n1p1 rm01rootfs
sudo e2label /dev/nvme0n1p2 rm01cfe
sudo e2label /dev/sda2 rm01cfe
# 验证标签
sudo blkid /dev/nvme0n1p1
sudo blkid /dev/nvme0n1p2




# 分区与格式化 载入分区配置文件 rm01_cfe_layout
sudo mkfs.ext4 /dev/sda1
sudo e2label /dev/sda1 rm01rootfs
sudo blkid  /dev/sda1

sudo mkfs.ext4 /dev/sda16
sudo e2label /dev/sda16 rm01models
sudo e2label /dev/nvme0n1p16 rm01models
sudo blkid  /dev/sda16

sudo mkfs.exfat /dev/sda17
sudo exfatlabel /dev/sda3 rm01app
sudo exfatlabel /dev/nvme0n1p17 rm01app
sudo exfatlabel /dev/sda3
```

#### （三）创建挂载点

``` bash
mkdir -p /home/rm01/cfe
```

#### （四）启用自动挂载 (修改/etc/fstab文件，添加如下配置)

```bash
# 使用exfat格式
LABEL=rm01cfe /home/rm01/cfe exfat-fuse defaults,nofail 0 2

# 使用ext4格式
LABEL=rm01cfe /home/rm01/cfe ext4 defaults,nofail 0 2
```

#### 参数说明 ：

- LABEL=rm01cfe：通过 LABEL 唯一标识硬盘。
- /mnt/nvme：挂载点目录。
- ext4：文件系统类型（根据实际情况调整，如 xfs、ntfs 等）。
- defaults,nofail：
  - defaults：使用默认挂载选项。
  - nofail：即使硬盘不存在也不影响系统启动。
- 0 2：
  - 第一个 0：表示不备份。
  - 第二个 2：表示文件系统检查顺序（根分区为 1，其他分区为 2 或 0）。

#### （五）测试配置与查看挂载情况

``` bash
# 测试配置
sudo mount -a

# 查看挂载情况
lsblk
```

创建自动拉起服务

https://x.com/i/grok?conversation=1933726835927625841

目录结构

``` bash
# 自动拉起模型目录（直接在其中放模型文件）
/home/rm01/cfe/auto/llm
/home/rm01/cfe/auto/embedding
/home/rm01/cfe/auto/reranker

# ISV开发者拉起脚本
/home/rm01/cfe/models/dev/llm_run.sh
/home/rm01/cfe/models/dev/embedding_run.sh
/home/rm01/cfe/models/dev/reranker_run.sh

# ISV开发者模型目录（按照需要放置目录）
/home/rm01/cfe/models/llm
/home/rm01/cfe/models/embedding
/home/rm01/cfe/models/reranker


# 大语言模型测试
curl http://10.10.99.98:58000/v1/chat/completions \
    -H "Content-Type: application/json" \
    -d '{
        "model": "RM-01 LLM",
        "messages": [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "Who won the world series in 2020?"}
        ]
    }'
    
    
curl http://10.10.99.98:58000/v1/completions \
    -H "Content-Type: application/json" \
    -d '{
        "model": "RM-01 LLM",
        "prompt": "San Francisco is a",
        "max_tokens": 7,
        "temperature": 0
    }'
    
    # 嵌入模型测试
curl 10.10.99.98:58080/embed \
    -X POST \
    -d '{"inputs":"What is Deep Learning?"}' \
    -H 'Content-Type: application/json'
# 重排序模型测试
curl 10.10.99.98:58081/rerank \
    -X POST \
    -d '{"query": "What is Deep Learning?", "texts": ["Deep Learning is not...", "Deep learning is..."]}' \
    -H 'Content-Type: application/json'
    
    
    
    # 检查默认自动拉起服务
    sudo systemctl status auto-embedding.service auto-reranker.service auto-llm.service
    # 检查ISV自定义自动拉起服务
    sudo systemctl status dev-embedding.service dev-reranker.service dev-llm.service
    
    sudo systemctl stop dev-reranker.service
    # 查看服务日志
    journalctl -u dev-reranker.service -f
    journalctl -u dev-embedding.service -f
    journalctl -u dev-llm.service -f
```

镜像备份

``` bash
sudo systemctl disable NetworkManager-wait-online.service
sudo systemctl set-default multi-user.target
sudo systemctl disable nv-l4t-usb-device-mode.service
sudo systemctl mask nv-l4t-usb-device-mode.service

sudo ./flash.sh -r -k APP -G rm01-20250614.img rm01-orin mmcblk0p1
```





## 发行卡

创建根

``` bash
# 创建内部存储镜像
sudo  BOARDID=3701 BOARDSKU=0005 FAB=501 BOARDREV=G.0 ./tools/kernel_flash/l4t_initrd_flash.sh --no-flash rm01-orin nvme0n1p1
# 查看生成情况
ls -lh /home/rm01/nvidia/nvidia_sdk/JetPack_6.2_Linux_JETSON_AGX_ORIN_TARGETS/Linux_for_Tegra/tools/kernel_flash/images/internal/

# 创建nvme镜像
sudo BOARDID=3701 BOARDSKU=0005 FAB=501 BOARDREV=G.0  ADDITIONAL_DTB_OVERLAY_OPT="BootOrderNvme.dtbo" ./tools/kernel_flash/l4t_initrd_flash.sh --direct sda1 -c tools/kernel_flash//flash_l4t_t234_nvme.xml --external-device nvme0n1p1 --no-flash -S 107374182400 rm01-orin nvme0n1p1
# 查看生成情况
ls -lh /home/rm01/nvidia/nvidia_sdk/JetPack_6.2_Linux_JETSON_AGX_ORIN_TARGETS/Linux_for_Tegra/tools/kernel_flash/images/external/system.img
```

### 烧录QSPI

``` bash
sudo ./flash.sh --no-systemimg --qspi-only --sparseupdate -c bootloader/generic/cfg/flash_t234_qspi.xml rm01-orin nvme0n1p1
```

将 CFE Type-B 插入 Host 根据 lsblk 查看具体的设备路径 使用外置读卡器路径为 /dev/sda1

### 烧录CFE Type-B

``` bash
sudo ./tools/kernel_flash/l4t_initrd_flash.sh --flash-only -c tools/kernel_flash//flash_l4t_t234_nvme.xml -k APP --external-device nvme0n1p1 --direct sda1  -S 107374182400 rm01-orin external
# 同步写入
sudo sync
```

## 完成黄金根创建后导出

``` bash
# 将完成制作的黄金根导出
sudo dd if=/dev/sda1 of=/home/rm01/testrootfs.img bs=4M status=progress oflag=direct




sudo  BOARDID=3701 BOARDSKU=0005 FAB=501 BOARDREV=G.0  ./tools/kernel_flash/l4t_initrd_flash.sh --initrd rm01-orin nvme0n1p1


# 在 Host 上操作
sudo dd if=/dev/sda1 of=rm01rootfs.img.raw status=progress
# 稀疏化镜像
./nvidia/nvidia_sdk/JetPack_6.2_Linux_JETSON_AGX_ORIN_TARGETS/Linux_for_Tegra/bootloader/mksparse rm01rootfs.img.raw rm01rootfs.img
# 复制到烧录插座
sudo cp rm01rootfs.img /home/rm01/nvidia/nvidia_sdk/JetPack_6.2_Linux_JETSON_AGX_ORIN_TARGETS/Linux_for_Tegra/tools/kernel_flash/images/external/system.img


# 烧录测试
 cd nvidia/nvidia_sdk/JetPack_6.2_Linux_JETSON_AGX_ORIN_TARGETS/Linux_for_Tegra/
 
```





## 安全启动

``` bash
# 进入 bootloader
cd ~/nvidia/nvidia_sdk/JetPack_6.2_Linux_JETSON_AGX_ORIN_TARGETS/Linux_for_Tegra/bootloader/

# 生成 RSA 3K 密钥
openssl genrsa -out rsa3k.pem 3072

# 生成公钥和公钥哈希
./tegrasign_v3.py --pubkeyhash rsa3k.pubkey rsa3k.hash --key rsa3k.pem

# 查看哈希
xxd -p rsa3k.hash
```

``` bash
# 结果如下
Key size is 384 bytes
Saving pkc public key in rsa3k.pubkey
Sha saved in pcp.sha
tegra-fuse format (big-endian): 0x87d383f9fe181e71fdd895f6ce9127ad1ed72fe1c93efc4a27682e798324573b611638b2c86205b023a2cd011ecd757087f540bd3787102f4b5e737a906b9cb7
```

``` bash
# 生成SBK
openssl rand -hex 32 > sbk_key.txt

# 查看SBK
cat sbk_key.txt

# 验证密钥文件 （输出值应该为65，64字节）
wc -c sbk_key.txt

# 生成 K1 和 K2
openssl rand -hex 32 > k1_key.txt
openssl rand -hex 32 > k2_key.txt

# 验证 K1 和 K2
cat k1_key.txt
cat k2_key.txt

# 创建包含 K1 和 K2 的文件
echo -n "$(cat k1_key.txt)$(cat k2_key.txt)" > eks_keys.txt

# 验证文件大小 128 字节
wc -c eks_keys.txt


```





## 编译设备树

``` bash
dtc -I dts -O dtb -o kernel/dtb/tegra234-rm01+p3701-0005-nv.dtb kernel/tegra234-rm01+p3701-0005-nv.dts 
```





## LP 串口配置

``` bash



# BIOS UART 转发

# Ubuntu 串口转发
sudo nano /etc/default/grub
# GRUB_CMDLINE_LINUX="console=tty1 console=ttyS0,115200n8"
sudo update-grub
# 更新 initramfs
sudo update-initramfs -u



# 创建镜像
sudo apt install gddrescue
sudo ddrescue /dev/sda1 ~/rm01rootfs.img ~/ddrescue1.log
sudo ddrescue /dev/sda2 ~/rm01cfe.img ~/ddrescue2.log



# 确认磁盘没有被挂载
mount | grep sda1
sudo umount /dev/sda1
# 还原镜像
sudo dd if=rm01rootfs.img of=/dev/sda1 bs=4M status=progress
sudo dd if=rm01cfe.img of=/dev/sda2 bs=4M status=progress

# 同步写入
sudo sync
```





## 安装 TIO 并添加 xterm-256color

``` bash
sudo apt update
sudo apt install tio

# 链接 ESP32S3
tio /dev/ttyCH343USB0
# 链接 AGX
tio /dev/ttyCH343USB1
# 链接 LP Mu N305
tio /dev/ttyCH343USB2
# 链接 ????
tio /dev/ttyCH343USB3

echo "export TERM=xterm-256color" >> ~/.bashrc
source ~/.bashrc
```





## 在线磁盘扩容(ext4)

``` bash
# 
sudo parted /dev/nvme0n1

# 提示符下输入
resizepart 1 100%

# 输入quit
quit

# 
sudo resize2fs /dev/nvme0n1p1

```

